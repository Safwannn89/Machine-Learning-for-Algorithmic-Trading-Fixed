{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote data access using pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas library enables access to data displayed on websites using the `read_html()` function and access to the API endpoints of various data providers through the related `pandas-datareader` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:06.402841Z",
     "start_time": "2020-06-16T16:31:06.398254Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mplfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:07.643241Z",
     "start_time": "2020-06-16T16:31:06.405846Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download html table with SP500 constituents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The download of the content of one or more html tables works as follows, for instance for the constituents of the S&P500 index from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:08.846591Z",
     "start_time": "2020-06-16T16:31:07.644941Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "sp_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "response = requests.get(sp_url)\n",
    "tables = pd.read_html(response.text)\n",
    "\n",
    "sp500_constituents = tables[0]\n",
    "print(sp500_constituents.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:08.964361Z",
     "start_time": "2020-06-16T16:31:08.854647Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp500_constituents.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:08.994696Z",
     "start_time": "2020-06-16T16:31:08.966011Z"
    }
   },
   "outputs": [],
   "source": [
    "sp500_constituents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas-datareader for Market Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` used to facilitate access to data providers' APIs directly, but this functionality has moved to the related pandas-datareader library. The stability of the APIs varies with provider policies, and as of June 2o18 at version 0.7, the following sources are available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [documentation](https://pandas-datareader.readthedocs.io/en/latest/); functionality frequently changes as underlying provider APIs evolve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:09.619351Z",
     "start_time": "2020-06-16T16:31:08.997931Z"
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "start = '2014-01-01'\n",
    "end = '2017-05-24'\n",
    "\n",
    "# Use yfinance to download data for Meta (formerly Facebook)\n",
    "yahoo = yf.download('META', start=start, end=end)\n",
    "\n",
    "# Show DataFrame\n",
    "print(yahoo.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "start = '2014-01-01'\n",
    "end = '2017-05-24'\n",
    "\n",
    "# Download data for META (formerly FB)\n",
    "yahoo = yf.download('META', start=start, end=end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten column MultiIndex\n",
    "yahoo.columns = yahoo.columns.get_level_values(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only drop 'Adj Close' if it exists\n",
    "if 'Adj Close' in yahoo.columns:\n",
    "    yahoo = yahoo.drop('Adj Close', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IEX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IEX is an alternative exchange started in response to the HFT controversy and portrayed in Michael Lewis' controversial Flash Boys. It aims to slow down the speed of trading to create a more level playing field and has been growing rapidly since launch in 2016 while still small with a market share of around 2.5% in June 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** IEX now requires an [API](https://iexcloud.io/) key after registration for (free) account that you can store as environment variable and retrieve as illustrated below, or pass directly via keyword argument to `pandas_datareader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:10.165605Z",
     "start_time": "2020-06-16T16:31:10.161455Z"
    }
   },
   "outputs": [],
   "source": [
    "IEX_API_KEY=os.getenv('IEX_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:10.536348Z",
     "start_time": "2020-06-16T16:31:10.167938Z"
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import mplfinance as mpf\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Download data for META (Facebook)\n",
    "start = '2015-02-09'\n",
    "end = '2017-05-24'\n",
    "yahoo = yf.download('META', start=start, end=end)\n",
    "\n",
    "# Step 2: Ensure column names are clean\n",
    "if isinstance(yahoo.columns, pd.MultiIndex):\n",
    "    yahoo.columns = yahoo.columns.get_level_values(0)\n",
    "\n",
    "# Step 3: Set index name for mplfinance\n",
    "yahoo.index.name = 'Date'\n",
    "\n",
    "# Step 4: Plot candlestick chart with volume\n",
    "mpf.plot(yahoo, type='candle', volume=True, title='META Candlestick Chart')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:10.562347Z",
     "start_time": "2020-06-16T16:31:10.538917Z"
    }
   },
   "outputs": [],
   "source": [
    "yahoo.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:10.873114Z",
     "start_time": "2020-06-16T16:31:10.568669Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Plot 'Close' prices from yahoo instead of iex\n",
    "yahoo['Close'].plot(figsize=(14, 5), title='META Close Price')\n",
    "sns.despine()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book Data\n",
    "\n",
    "In addition to historical EOD price and volume data, IEX provides real-time depth of book quotations that offer an aggregated size of orders by price and side. This service also includes last trade price and size information.\n",
    "\n",
    "DEEP is used to receive real-time depth of book quotations direct from IEX. The depth of book quotations received via DEEP provide an aggregated size of resting displayed orders at a price and side, and do not indicate the size or number of individual orders at any price level. Non-displayed orders and non-displayed portions of reserve orders are not represented in DEEP.\n",
    "\n",
    "DEEP also provides last trade price and size information. Trades resulting from either displayed or non-displayed orders matching on IEX will be reported. Routed executions will not be reported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only works on trading days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:11.041674Z",
     "start_time": "2020-06-16T16:31:10.878170Z"
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "data = yf.Ticker(\"AAPL\")\n",
    "book_data = data.history(period=\"1d\", interval=\"1m\")\n",
    "print(book_data.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:11.053523Z",
     "start_time": "2020-06-16T16:31:11.044219Z"
    }
   },
   "outputs": [],
   "source": [
    "list(book_data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:11.081754Z",
     "start_time": "2020-06-16T16:31:11.056964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using dummy order book data since 'book' was not defined earlier\n",
    "# 'bids' and 'asks' represent price and volume levels on each side of the order book\n",
    "\n",
    "book = {\n",
    "    'bids': [[100.5, 200], [100.4, 150], [100.3, 100]],\n",
    "    'asks': [[100.6, 250], [100.7, 180], [100.8, 120]]\n",
    "}\n",
    "\n",
    "# Combine bids and asks into a single DataFrame with a 'side' column\n",
    "orders = pd.concat([\n",
    "    pd.DataFrame(book[side], columns=['price', 'volume']).assign(side=side)\n",
    "    for side in ['bids', 'asks']\n",
    "])\n",
    "\n",
    "orders.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:11.134468Z",
     "start_time": "2020-06-16T16:31:11.087324Z"
    }
   },
   "outputs": [],
   "source": [
    "for key in book.keys():\n",
    "    try:\n",
    "        print(f'\\n{key}')\n",
    "        print(pd.DataFrame(book[key]))\n",
    "    except:\n",
    "        print(book[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dummy 'trades' data to the book\n",
    "book['trades'] = [\n",
    "    {'price': 100.55, 'volume': 50, 'timestamp': '2025-07-15 10:00:01'},\n",
    "    {'price': 100.60, 'volume': 30, 'timestamp': '2025-07-15 10:00:02'},\n",
    "    {'price': 100.58, 'volume': 20, 'timestamp': '2025-07-15 10:00:03'}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:11.172369Z",
     "start_time": "2020-06-16T16:31:11.139798Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(book['trades']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quandl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain Quandl [API Key](https://www.quandl.com/tools/api) and store in environment variable as `QUANDL_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:11.863946Z",
     "start_time": "2020-06-16T16:31:11.180937Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.3. Quandl\n",
    "# The original code used Quandl API, but due to access issues and deprecation of WIKI/FB dataset,\n",
    "# we are using Yahoo Finance instead for historical stock data.\n",
    "\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "# Download Facebook (Meta) stock data\n",
    "data = yf.download(\"META\", start=\"2015-01-01\", end=\"2025-01-01\")\n",
    "\n",
    "# Show info\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:12.385174Z",
     "start_time": "2020-06-16T16:31:11.865572Z"
    }
   },
   "outputs": [],
   "source": [
    "start = datetime(2010, 1, 1)\n",
    "\n",
    "end = datetime(2013, 1, 27)\n",
    "\n",
    "gdp = web.DataReader('GDP', 'fred', start, end)\n",
    "\n",
    "gdp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:13.081034Z",
     "start_time": "2020-06-16T16:31:12.386552Z"
    }
   },
   "outputs": [],
   "source": [
    "inflation = web.DataReader(['CPIAUCSL', 'CPILFESL'], 'fred', start, end)\n",
    "inflation.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fama/French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:13.295565Z",
     "start_time": "2020-06-16T16:31:13.082676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the Fama-French 3-Factor dataset starting from 2010\n",
    "# This dataset contains market, SMB (size), and HML (value) factor returns\n",
    "# from Kenneth French's data library\n",
    "\n",
    "from pandas_datareader import data\n",
    "ds = data.DataReader(\"F-F_Research_Data_Factors\", \"famafrench\", start='2010-01-01')\n",
    "\n",
    "# Display the keys (tables) in the dataset, such as monthly data and description\n",
    "print(ds.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:13.685900Z",
     "start_time": "2020-06-16T16:31:13.297565Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = web.DataReader('5_Industry_Portfolios', 'famafrench')\n",
    "print(ds['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### World Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:20.351157Z",
     "start_time": "2020-06-16T16:31:13.687743Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas_datareader import wb\n",
    "gdp_variables = wb.search('gdp.*capita.*const')\n",
    "gdp_variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:20.495020Z",
     "start_time": "2020-06-16T16:31:20.352495Z"
    }
   },
   "outputs": [],
   "source": [
    "wb_data = wb.download(indicator='NY.GDP.PCAP.KD', \n",
    "                      country=['US', 'CA', 'MX'], \n",
    "                      start=1990, \n",
    "                      end=2019)\n",
    "wb_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OECD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:21.557343Z",
     "start_time": "2020-06-16T16:31:20.499816Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas_datareader import data as web\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download GDP data from FRED\n",
    "df = web.DataReader('GDP', 'fred', start='2010', end='2019')\n",
    "\n",
    "# Plot\n",
    "df.plot(title='US GDP (2010–2019)', figsize=(12, 5))\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EuroStat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:24.338547Z",
     "start_time": "2020-06-16T16:31:21.561928Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas_datareader import data as web\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# US Unemployment Rate from FRED\n",
    "df = web.DataReader('UNRATE', 'fred', start='2010', end='2020')\n",
    "df.plot(title='US Unemployment Rate (2010–2020)', figsize=(12, 5))\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:24.437638Z",
     "start_time": "2020-06-16T16:31:24.348309Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Stooq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google finance stopped providing common index data download. The Stooq site had this data for download for a while but is currently broken, awaiting release of [fix](https://github.com/pydata/pandas-datareader/issues/594)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:25.992153Z",
     "start_time": "2020-06-16T16:31:24.443075Z"
    }
   },
   "outputs": [],
   "source": [
    "index_url = 'https://stooq.com/t/'\n",
    "ix = pd.read_html(index_url)\n",
    "len(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:26.758508Z",
     "start_time": "2020-06-16T16:31:25.997057Z"
    }
   },
   "outputs": [],
   "source": [
    "sp500_stooq = web.DataReader('^SPX', 'stooq')\n",
    "sp500_stooq.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:26.786322Z",
     "start_time": "2020-06-16T16:31:26.763785Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp500_stooq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the S&P 500 closing prices\n",
    "sp500_stooq.Close.plot(figsize=(14, 4))\n",
    "\n",
    "# Remove top and right spines for a cleaner look\n",
    "sns.despine()\n",
    "\n",
    "# Adjust subplot spacing\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:27.366773Z",
     "start_time": "2020-06-16T16:31:26.791344Z"
    }
   },
   "outputs": [],
   "source": [
    "sp500_stooq.Close.plot(figsize=(14,4))\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASDAQ Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:27.604494Z",
     "start_time": "2020-06-16T16:31:27.372483Z"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# ✅ Replacement for failed Nasdaq FTP data fetch\n",
    "# -----------------------------------------\n",
    "# The original code used this URL to fetch NASDAQ symbols:\n",
    "# url = \"https://ftp.nasdaqtrader.com/dynamic/SymDir/nasdaqtraded.txt\"\n",
    "# However, this method failed with a timeout (WinError 10060) due to network restrictions,\n",
    "# server issues, or because the FTP server is no longer reliable or accessible.\n",
    "\n",
    "# ✅ Instead, we're now using the Wikipedia page listing all S&P 500 companies,\n",
    "# which is more stable, up-to-date, and easy to parse using pandas.\n",
    "# -----------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO  # ✅ Used to fix the FutureWarning from read_html\n",
    "\n",
    "# Step 1: Define the URL of the Wikipedia page listing S&P 500 companies\n",
    "sp_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "\n",
    "# Step 2: Send an HTTP GET request to fetch the page content\n",
    "response = requests.get(sp_url)\n",
    "\n",
    "# Step 3: Wrap HTML content with StringIO to avoid FutureWarning\n",
    "html_content = StringIO(response.text)\n",
    "\n",
    "# Step 4: Use pandas to extract all tables from the HTML content\n",
    "tables = pd.read_html(html_content)\n",
    "\n",
    "# Step 5: The first table on the page (index 0) contains the S&P 500 constituents\n",
    "sp500_constituents = tables[0]\n",
    "\n",
    "# Step 6: Display the first 5 rows to confirm the structure of the table\n",
    "print(sp500_constituents.head())\n",
    "\n",
    "# Step 7 (Optional): Extract just the stock symbols for further use (like downloading price data)\n",
    "symbols = sp500_constituents['Symbol'].tolist()\n",
    "print(\"\\nTotal symbols extracted:\", len(symbols))\n",
    "print(\"Sample symbols:\", symbols[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiingo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requires [signing up](https://api.tiingo.com/) and storing API key in environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:27.807212Z",
     "start_time": "2020-06-16T16:31:27.609921Z"
    }
   },
   "outputs": [],
   "source": [
    "df = web.get_data_tiingo('GOOG', api_key=os.getenv('TIINGO_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:31:27.834076Z",
     "start_time": "2020-06-16T16:31:27.812635Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
